"""
train.py - Entra√Ænement du mod√®le de d√©tection de fraude

Ce fichier fait 5 choses simples :
1. Charger les donn√©es (le CSV)
2. Pr√©parer les donn√©es (s√©parer X et y, normaliser)
3. Entra√Æner 2 mod√®les (Logistic Regression et Random Forest)
4. Comparer les performances
5. Sauvegarder le meilleur mod√®le

Auteur : Ton Nom
Date : Jour 3-4
"""

# ====================
# IMPORTS (biblioth√®ques n√©cessaires)
# ====================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    f1_score,
    recall_score,
    precision_score,
    roc_auc_score
)
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 50)
print("D√âTECTION DE FRAUDE - ENTRA√éNEMENT DU MOD√àLE")
print("=" * 50)

# ====================
# √âTAPE 1 : CHARGER LES DONN√âES
# ====================
print("\n[1/5] Chargement du dataset...")

# Charger le fichier CSV
df = pd.read_csv('/home/ousmane/projects/fraud-detection-devops/data/creditcard.csv')

print(f"‚úÖ Dataset charg√© : {df.shape[0]} transactions, {df.shape[1]} colonnes")
print(f"   - Transactions normales : {(df['Class']==0).sum()}")
print(f"   - Transactions frauduleuses : {(df['Class']==1).sum()}")

# ====================
# √âTAPE 2 : PR√âPARER LES DONN√âES
# ====================
print("\n[2/5] Pr√©paration des donn√©es...")

# 2.1 S√©parer X (features) et y (target)
# X = toutes les colonnes SAUF 'Class'
# y = seulement la colonne 'Class'
X = df.drop('Class', axis=1)  # axis=1 = supprimer colonne
y = df['Class']

print(f"‚úÖ Features (X) : {X.shape}")
print(f"‚úÖ Target (y) : {y.shape}")

# 2.2 Diviser en train/test (80% train, 20% test)
# stratify=y : garde le m√™me ratio fraude/normal dans train et test
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,      # 20% pour test
    random_state=42,    # Pour avoir toujours le m√™me split
    stratify=y          # Garde ratio 0.17% dans train et test
)

print(f"‚úÖ Train set : {X_train.shape[0]} transactions")
print(f"‚úÖ Test set : {X_test.shape[0]} transactions")

# 2.3 Normaliser les donn√©es (StandardScaler)
# Formule : (x - moyenne) / √©cart-type
# R√©sultat : tous les nombres entre -3 et +3
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"‚úÖ Donn√©es normalis√©es (moyenne=0, √©cart-type=1)")

# Sauvegarder le scaler (important pour plus tard !)
joblib.dump(scaler, '/home/ousmane/projects/fraud-detection-devops/models/scaler.pkl')
print(f"‚úÖ Scaler sauvegard√© dans models/scaler.pkl")

# ====================
# √âTAPE 3 : ENTRA√éNER LES MOD√àLES
# ====================
print("\n[3/5] Entra√Ænement des mod√®les...")

# ------------------------------
# MOD√àLE 1 : LOGISTIC REGRESSION
# ------------------------------
print("\nüìä Mod√®le 1 : Logistic Regression")
print("-" * 40)

# Cr√©er le mod√®le
# class_weight='balanced' : donne plus d'importance aux fraudes (rare)
lr_model = LogisticRegression(
    class_weight='balanced',
    random_state=42,
    max_iter=1000  # Nombre d'it√©rations pour apprendre
)

# Entra√Æner (le mod√®le apprend ici !)
print("‚è≥ Entra√Ænement en cours...")
lr_model.fit(X_train_scaled, y_train)
print("‚úÖ Entra√Ænement termin√© !")

# Pr√©dire sur le test
y_pred_lr = lr_model.predict(X_test_scaled)
y_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]  # Probabilit√© classe 1

# Calculer les performances
lr_f1 = f1_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_precision = precision_score(y_test, y_pred_lr)
lr_auc = roc_auc_score(y_test, y_proba_lr)

print(f"\nüìà Performances Logistic Regression :")
print(f"   - F1-Score    : {lr_f1:.4f}")
print(f"   - Recall      : {lr_recall:.4f} ({lr_recall*100:.1f}% fraudes d√©tect√©es)")
print(f"   - Precision   : {lr_precision:.4f} ({lr_precision*100:.1f}% alertes correctes)")
print(f"   - AUC-ROC     : {lr_auc:.4f}")

# ------------------------------
# MOD√àLE 2 : RANDOM FOREST
# ------------------------------
print("\nüå≤ Mod√®le 2 : Random Forest")
print("-" * 40)

# Cr√©er le mod√®le
# n_estimators=100 : 100 arbres de d√©cision
rf_model = RandomForestClassifier(
    n_estimators=100,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1  # Utilise tous les CPU
)

# Entra√Æner
print("‚è≥ Entra√Ænement en cours (plus long que Logistic Regression)...")
rf_model.fit(X_train_scaled, y_train)
print("‚úÖ Entra√Ænement termin√© !")

# Pr√©dire
y_pred_rf = rf_model.predict(X_test_scaled)
y_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]

# Performances
rf_f1 = f1_score(y_test, y_pred_rf)
rf_recall = recall_score(y_test, y_pred_rf)
rf_precision = precision_score(y_test, y_pred_rf)
rf_auc = roc_auc_score(y_test, y_proba_rf)

print(f"\nüìà Performances Random Forest :")
print(f"   - F1-Score    : {rf_f1:.4f}")
print(f"   - Recall      : {rf_recall:.4f} ({rf_recall*100:.1f}% fraudes d√©tect√©es)")
print(f"   - Precision   : {rf_precision:.4f} ({rf_precision*100:.1f}% alertes correctes)")
print(f"   - AUC-ROC     : {rf_auc:.4f}")

# ====================
# √âTAPE 4 : COMPARER LES MOD√àLES
# ====================
print("\n[4/5] Comparaison des mod√®les...")
print("=" * 50)

# Tableau comparatif
comparison = pd.DataFrame({
    'Mod√®le': ['Logistic Regression', 'Random Forest'],
    'F1-Score': [lr_f1, rf_f1],
    'Recall': [lr_recall, rf_recall],
    'Precision': [lr_precision, rf_precision],
    'AUC-ROC': [lr_auc, rf_auc]
})

print("\nüìä COMPARAISON DES PERFORMANCES :")
print(comparison.to_string(index=False))

# Choisir le meilleur mod√®le (bas√© sur F1-Score)
if rf_f1 > lr_f1:
    best_model = rf_model
    best_model_name = "Random Forest"
    best_f1 = rf_f1
    y_pred_best = y_pred_rf
else:
    best_model = lr_model
    best_model_name = "Logistic Regression"
    best_f1 = lr_f1
    y_pred_best = y_pred_lr

print(f"\nüèÜ MEILLEUR MOD√àLE : {best_model_name} (F1={best_f1:.4f})")

# ====================
# √âTAPE 5 : SAUVEGARDER LE MEILLEUR MOD√àLE
# ====================
print("\n[5/5] Sauvegarde du mod√®le...")

# Sauvegarder
model_path = '/home/ousmane/projects/fraud-detection-devops/models/fraud_detector.pkl'
joblib.dump(best_model, model_path)
print(f"‚úÖ Mod√®le sauvegard√© dans : {model_path}")

# Sauvegarder aussi les m√©tadonn√©es
metadata = {
    'model_name': best_model_name,
    'f1_score': best_f1,
    'recall': recall_score(y_test, y_pred_best),
    'precision': precision_score(y_test, y_pred_best),
    'auc_roc': roc_auc_score(y_test, y_proba_rf if best_model_name == "Random Forest" else y_proba_lr),
    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'train_size': len(X_train),
    'test_size': len(X_test)
}

joblib.dump(metadata, '/home/ousmane/projects/fraud-detection-devops/models/metadata.pkl')
print(f"‚úÖ M√©tadonn√©es sauvegard√©es dans : models/metadata.pkl")

# ====================
# VISUALISATIONS
# ====================
print("\nüìä G√©n√©ration des visualisations...")

# Cr√©er dossier pour les images si n'existe pas
import os
os.makedirs('./home/ousmane/projects/fraud-detection-devops/docs/images', exist_ok=True)

# 1. Matrice de confusion
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred_best)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title(f'Matrice de Confusion - {best_model_name}')
plt.ylabel('Vraie Classe')
plt.xlabel('Classe Pr√©dite')
plt.savefig('/home/ousmane/projects/fraud-detection-devops/docs/images/confusion_matrix.png', dpi=300, bbox_inches='tight')
print("‚úÖ Matrice de confusion sauvegard√©e")

# 2. Feature Importance (si Random Forest)
if best_model_name == "Random Forest":
    plt.figure(figsize=(10, 8))
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False).head(15)
    
    sns.barplot(data=feature_importance, x='importance', y='feature')
    plt.title('Top 15 Features les plus importantes')
    plt.xlabel('Importance')
    plt.savefig('/home/ousmane/projects/fraud-detection-devops/docs/images/feature_importance.png', dpi=300, bbox_inches='tight')
    print("‚úÖ Feature importance sauvegard√©e")

plt.close('all')

# ====================
# RAPPORT D√âTAILL√â
# ====================
print("\n" + "=" * 50)
print("RAPPORT FINAL")
print("=" * 50)

print(f"\nüéØ Mod√®le s√©lectionn√© : {best_model_name}")
print(f"\nüìä M√©triques sur le test set :")
print(classification_report(y_test, y_pred_best, 
                          target_names=['Normal', 'Fraude']))

print(f"\nüìà Interpr√©tation :")
print(f"   Sur {len(y_test)} transactions de test :")
print(f"   - {(y_test==0).sum()} normales")
print(f"   - {(y_test==1).sum()} frauduleuses")
print(f"\n   Le mod√®le a :")
print(f"   - D√©tect√© {(y_pred_best[y_test==1]==1).sum()} fraudes sur {(y_test==1).sum()}")
print(f"   - Rat√© {(y_pred_best[y_test==1]==0).sum()} fraudes")
print(f"   - Cr√©√© {(y_pred_best[y_test==0]==1).sum()} fausses alertes")

print("\n‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS !")
print("=" * 50)

# ====================
# INSTRUCTIONS POUR UTILISER LE MOD√àLE
# ====================
print("\nüìñ COMMENT UTILISER LE MOD√àLE :")
print("""
1. Charger le mod√®le :
   import joblib
   model = joblib.load('models/fraud_detector.pkl')
   scaler = joblib.load('models/scaler.pkl')

2. Pr√©parer une nouvelle transaction :
   new_transaction = [[V1, V2, ..., V28, Time, Amount]]
   new_transaction_scaled = scaler.transform(new_transaction)

3. Pr√©dire :
   prediction = model.predict(new_transaction_scaled)
   # 0 = Normal, 1 = Fraude

4. Probabilit√© :
   probability = model.predict_proba(new_transaction_scaled)[:, 1]
   # Valeur entre 0 et 1
""")